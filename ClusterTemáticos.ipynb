{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5wbqxQVtopb45hdtUd6Fp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanfisicobr/Red-coocurrencia-terminos/blob/main/ClusterTem%C3%A1ticos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLE0acuJ95U9",
        "outputId": "c4532b1c-cb11-44b7-d45e-1dd3ce38d46b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.3.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.2)\n",
            "Requirement already satisfied: python-louvain in /usr/local/lib/python3.12/dist-packages (0.16)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.7)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (3.5)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (12.0.0)\n",
            "Requirement already satisfied: pyparsing>=3 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas nltk python-louvain matplotlib networkx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import re\n",
        "from itertools import combinations\n",
        "import community as community_louvain\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def preprocess_text(text, custom_stopwords=None):\n",
        "    mapa_normalizacao = {\n",
        "        'investigaciones': 'investigacion',\n",
        "        'docentes': 'docente',\n",
        "        'estudiantes': 'estudiante',\n",
        "        'sociales': 'social',\n",
        "        'educacionales': 'educacional',\n",
        "        'nacionales': 'nacional',\n",
        "        'regionales': 'regional',\n",
        "        'locales': 'local',\n",
        "        'institucionales': 'institucional',\n",
        "        'profesionales': 'profesional',\n",
        "        'populares': 'popular',\n",
        "        'municipales': 'municipal',\n",
        "        'políticas': 'política',\n",
        "        'acciones': 'accion',\n",
        "        'redes': 'red',\n",
        "        'universidades': 'universidad'\n",
        "    }\n",
        "    stop_words = set(['de', 'a', 'o', 'que', 'y', 'e', 'el', 'la', 'en', 'un', 'una', 'para',\n",
        "        'con', 'no', 'los', 'las', 'por', 'mas', 'más', 'se', 'su', 'sus',\n",
        "        'como', 'pero', 'al', 'del', 'le', 'lo', 'me', 'mi', 'sin', 'son',\n",
        "        'tambien', 'también', 'este', 'esta', 'estos', 'estas', 'ser', 'es'])\n",
        "    if custom_stopwords:\n",
        "        stop_words.update(custom_stopwords)\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    tokens = text.split()\n",
        "    normalized_tokens = [mapa_normalizacao.get(token, token) for token in tokens]\n",
        "    filtered_tokens = [word for word in normalized_tokens if word not in stop_words and len(word) > 2]\n",
        "    return filtered_tokens\n",
        "\n",
        "def create_cooccurrence_matrix_from_file(filepath):\n",
        "    with open(filepath, 'r', encoding='utf-8') as file:\n",
        "        content = file.read()\n",
        "    documents_raw = content.split('###')\n",
        "    documents_raw = [doc.strip() for doc in documents_raw if doc.strip()]\n",
        "    custom_stopwords = ['programa', 'educacion', 'pdi', 'art', 'articulo']\n",
        "    processed_docs = [preprocess_text(doc, custom_stopwords) for doc in documents_raw]\n",
        "    vocabulary = sorted(list(set(term for doc in processed_docs for term in doc)))\n",
        "    M = pd.DataFrame(0, index=vocabulary, columns=vocabulary)\n",
        "    for doc in processed_docs:\n",
        "        unique_terms_in_doc = sorted(list(set(doc)))\n",
        "        for term in unique_terms_in_doc:\n",
        "            M.loc[term, term] += 1\n",
        "        for term1, term2 in combinations(unique_terms_in_doc, 2):\n",
        "            M.loc[term1, term2] += 1\n",
        "            M.loc[term2, term1] += 1\n",
        "    return M\n",
        "\n",
        "def calcular_e_associar_metricas(G, M):\n",
        "    partition = community_louvain.best_partition(G, weight='weight')\n",
        "    pagerank = nx.pagerank(G, weight='weight')\n",
        "    occurrences = {term: M.loc[term, term] for term in G.nodes()}\n",
        "    clusters_ajustados = {node: cluster_id + 1 for node, cluster_id in partition.items()}\n",
        "    nx.set_node_attributes(G, clusters_ajustados, 'cluster')\n",
        "    nx.set_node_attributes(G, pagerank, 'pagerank')\n",
        "    nx.set_node_attributes(G, occurrences, 'occurrences')\n",
        "    print(\"Métricas (Cluster, PageRank, Ocorrencias) calculadas y asociadas a los nodos.\")\n",
        "    return G\n",
        "\n",
        "def filtrar_rede(G, top_n, min_edge_weight_for_viz):\n",
        "    if G.number_of_nodes() <= top_n:\n",
        "        top_nodes = list(G.nodes())\n",
        "    else:\n",
        "        pagerank_dict = nx.get_node_attributes(G, 'pagerank')\n",
        "        sorted_nodes = sorted(pagerank_dict, key=pagerank_dict.get, reverse=True)\n",
        "        top_nodes = sorted_nodes[:top_n]\n",
        "    G_sub = G.subgraph(top_nodes).copy()\n",
        "    G_final = nx.Graph()\n",
        "    G_final.add_nodes_from(G_sub.nodes(data=True))\n",
        "    for u, v, data in G_sub.edges(data=True):\n",
        "        if data['weight'] >= min_edge_weight_for_viz:\n",
        "            G_final.add_edge(u, v, weight=data['weight'])\n",
        "    G_final.remove_nodes_from(list(nx.isolates(G_final)))\n",
        "    print(f\"Red final (Top {top_n} nodos, Bordes >= {min_edge_weight_for_viz}): {G_final.number_of_nodes()} nodos, {G_final.number_of_edges()} bordes.\")\n",
        "    return G_final\n",
        "\n",
        "## ----------------------------------------------------------------\n",
        "## FUNCIÓN: Visualización de la Red\n",
        "## ----------------------------------------------------------------\n",
        "def visualizar_rede(G, title, output_filename):\n",
        "    if G.number_of_nodes() == 0:\n",
        "        print(\"La red está vacía. No es posible generar el gráfico.\")\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(16, 9))\n",
        "    pos = nx.circular_layout(G)\n",
        "\n",
        "    # Colores monocromáticos basados ​​en PageRank\n",
        "    pagerank_values = [data.get('pagerank', 0) for _, data in G.nodes(data=True)]\n",
        "    if pagerank_values:\n",
        "        min_pr = min(pagerank_values)\n",
        "        max_pr = max(pagerank_values)\n",
        "        if max_pr == min_pr:\n",
        "            norm_pr_values = [0.5] * len(pagerank_values)\n",
        "        else:\n",
        "            norm_pr_values = [(p - min_pr) / (max_pr - min_pr) for p in pagerank_values]\n",
        "    else:\n",
        "        norm_pr_values = []\n",
        "\n",
        "    cmap = plt.cm.get_cmap('Blues_r')\n",
        "    node_colors = [cmap(p) for p in norm_pr_values]\n",
        "\n",
        "    # Tamaño del nodo\n",
        "    min_size = 1500\n",
        "    max_size = 16000\n",
        "    if pagerank_values and min_pr == max_pr:\n",
        "        node_sizes = [min_size] * G.number_of_nodes()\n",
        "    elif pagerank_values:\n",
        "        node_sizes = [min_size + ((p - min_pr) / (max_pr - min_pr)) * (max_size - min_size) for p in pagerank_values]\n",
        "    else:\n",
        "        node_sizes = []\n",
        "\n",
        "    custom_labels = {\n",
        "        node: f\"{node.capitalize()}\\n({data.get('occurrences', '?')})\"\n",
        "        for node, data in G.nodes(data=True)\n",
        "    }\n",
        "\n",
        "\n",
        "    nx.draw_networkx_nodes(\n",
        "        G,\n",
        "        pos,\n",
        "        node_color=node_colors,\n",
        "        node_size=node_sizes,\n",
        "        alpha=0.7,\n",
        "        edgecolors='black',\n",
        "        linewidths=1.5\n",
        "    )\n",
        "\n",
        "    nx.draw_networkx_edges(G, pos, alpha=0.3, width=1.5, edge_color='grey')\n",
        "    nx.draw_networkx_labels(G, pos, labels=custom_labels, font_size=12, font_color='black', font_weight='bold')\n",
        "\n",
        "    plt.title(title, size=20)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_filename, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"\\nGráfico '{output_filename}' guardado con éxito!\")\n",
        "\n",
        "## ----------------------------------------------------------------\n",
        "## BLOQUE DE EJECUCIÓN PRINCIPAL\n",
        "## ----------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # --- Parámetros de Entrada ---\n",
        "    FILE_PATH = 'extractos.txt'\n",
        "    TOP_N_NODES = 20\n",
        "    MIN_EDGE_WEIGHT_VIZ = 4 # Ajuste para controlar la densidad de la línea.\n",
        "\n",
        "    GRAFICO_TITULO = \"Análisis de Red Monocromática\"\n",
        "    GRAFICO_OUTPUT_FILE = \"analisis_red_monocromatica.png\"\n",
        "\n",
        "    # --- Ejecución del flujo de trabajo ---\n",
        "    matriz_M = create_cooccurrence_matrix_from_file(FILE_PATH)\n",
        "    grafo_base = nx.from_pandas_adjacency(matriz_M)\n",
        "    grafo_com_metricas = calcular_e_associar_metricas(grafo_base, matriz_M)\n",
        "    grafo_final = filtrar_rede(grafo_com_metricas, top_n=TOP_N_NODES, min_edge_weight_for_viz=MIN_EDGE_WEIGHT_VIZ)\n",
        "    visualizar_rede(grafo_final, GRAFICO_TITULO, GRAFICO_OUTPUT_FILE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLjMLwlpNysn",
        "outputId": "203c11bb-5ade-494d-c460-5b0013a40b9c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Métricas (Cluster, PageRank, Ocorrencias) calculadas y asociadas a los nodos.\n",
            "Red final (Top 20 nodos, Bordes >= 4): 20 nodos, 74 bordes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3310999811.py:111: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
            "  cmap = plt.cm.get_cmap('Blues_r')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Gráfico 'analisis_red_monocromatica.png' guardado con éxito!\n"
          ]
        }
      ]
    }
  ]
}