{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOoUgWWnQYODzoDlYdBBDFT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanfisicobr/Red-coocurrencia-terminos/blob/main/ClusterTem%C3%A1ticos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLE0acuJ95U9"
      },
      "outputs": [],
      "source": [
        "!pip install pandas nltk python-louvain matplotlib networkx --force-reinstall"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import re\n",
        "from itertools import combinations\n",
        "import community as community_louvain\n",
        "import matplotlib.pyplot as plt\n",
        "import unicodedata\n",
        "import numpy as np\n",
        "\n",
        "def _eliminar_tildes(texto):\n",
        "    nfkd_form = unicodedata.normalize('NFD', texto)\n",
        "    return \"\".join([c for c in nfkd_form if unicodedata.category(c) != 'Mn'])\n",
        "\n",
        "def preprocess_text(text, custom_stopwords=None):\n",
        "    mapa_normalizacao = {\n",
        "        'investigaciones': 'investigacion',\n",
        "        'docentes': 'docente',\n",
        "        'estudiantes': 'estudiante',\n",
        "        'sociales': 'social',\n",
        "        'educacionales': 'educacional',\n",
        "        'nacionales': 'nacional',\n",
        "        'regionales': 'regional',\n",
        "        'locales': 'local',\n",
        "        'institucionales': 'institucional',\n",
        "        'profesionales': 'profesional',\n",
        "        'populares': 'popular',\n",
        "        'municipales': 'municipal',\n",
        "        'políticas': 'política',\n",
        "        'acciones': 'accion',\n",
        "        'redes': 'red',\n",
        "        'universidades': 'universidad'\n",
        "    }\n",
        "    stop_words = set(['de', 'a', 'o', 'que', 'y', 'e', 'el', 'la', 'en', 'un', 'una', 'para',\n",
        "        'con', 'no', 'los', 'las', 'por', 'mas', 'más', 'se', 'su', 'sus',\n",
        "        'como', 'pero', 'al', 'del', 'le', 'lo', 'me', 'mi', 'sin', 'son',\n",
        "        'tambien', 'también', 'este', 'esta', 'estos', 'estas', 'ser', 'es'])\n",
        "    if custom_stopwords:\n",
        "        stop_words.update(custom_stopwords)\n",
        "    text = text.lower()\n",
        "    text = _eliminar_tildes(text)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    tokens = text.split()\n",
        "    normalized_tokens = [mapa_normalizacao.get(token, token) for token in tokens]\n",
        "    filtered_tokens = [word for word in normalized_tokens if word not in stop_words and len(word) > 2]\n",
        "    return filtered_tokens\n",
        "\n",
        "def create_cooccurrence_matrix_from_file(filepath):\n",
        "    with open(filepath, 'r', encoding='utf-8') as file:\n",
        "        content = file.read()\n",
        "    documents_raw = content.split('###')\n",
        "    documents_raw = [doc.strip() for doc in documents_raw if doc.strip()]\n",
        "    custom_stopwords = ['programa', 'educacion', 'pdi', 'art', 'articulo', 'sobre']\n",
        "    processed_docs = [preprocess_text(doc, custom_stopwords) for doc in documents_raw]\n",
        "    vocabulary = sorted(list(set(term for doc in processed_docs for term in doc)))\n",
        "    M = pd.DataFrame(0, index=vocabulary, columns=vocabulary)\n",
        "    for doc in processed_docs:\n",
        "        unique_terms_in_doc = sorted(list(set(doc)))\n",
        "        for term in unique_terms_in_doc:\n",
        "            M.loc[term, term] += 1\n",
        "        for term1, term2 in combinations(unique_terms_in_doc, 2):\n",
        "            M.loc[term1, term2] += 1\n",
        "            M.loc[term2, term1] += 1\n",
        "    return M\n",
        "\n",
        "def calcular_e_associar_metricas(G, M):\n",
        "    partition = community_louvain.best_partition(G, weight='weight')\n",
        "    pagerank = nx.pagerank(G, weight='weight')\n",
        "    occurrences = {term: M.loc[term, term] for term in G.nodes()}\n",
        "    clusters_ajustados = {node: cluster_id + 1 for node, cluster_id in partition.items()}\n",
        "    nx.set_node_attributes(G, clusters_ajustados, 'cluster')\n",
        "    nx.set_node_attributes(G, pagerank, 'pagerank')\n",
        "    nx.set_node_attributes(G, occurrences, 'occurrences')\n",
        "    print(\"Métricas (Cluster, PageRank, Ocorrencias) calculadas y asociadas a los nodos.\")\n",
        "    return G\n",
        "\n",
        "def filtrar_rede(G, top_n, min_edge_weight_for_viz):\n",
        "    if G.number_of_nodes() <= top_n:\n",
        "        top_nodes = list(G.nodes())\n",
        "    else:\n",
        "        pagerank_dict = nx.get_node_attributes(G, 'pagerank')\n",
        "        sorted_nodes = sorted(pagerank_dict, key=pagerank_dict.get, reverse=True)\n",
        "        top_nodes = sorted_nodes[:top_n]\n",
        "    G_sub = G.subgraph(top_nodes).copy()\n",
        "    G_final = nx.Graph()\n",
        "    G_final.add_nodes_from(G_sub.nodes(data=True))\n",
        "    for u, v, data in G_sub.edges(data=True):\n",
        "        if data['weight'] >= min_edge_weight_for_viz:\n",
        "            G_final.add_edge(u, v, weight=data['weight'])\n",
        "    G_final.remove_nodes_from(list(nx.isolates(G_final)))\n",
        "    print(f\"Red final (Top {top_n} nodos, Bordes >= {min_edge_weight_for_viz}): {G_final.number_of_nodes()} nodos, {G_final.number_of_edges()} bordes.\")\n",
        "    return G_final\n",
        "\n",
        "## ----------------------------------------------------------------\n",
        "## FUNCIÓN: Visualización de la Red\n",
        "## ----------------------------------------------------------------\n",
        "def visualizar_rede(G, title, output_filename):\n",
        "    if G.number_of_nodes() == 0:\n",
        "        print(\"La red está vacía. No es posible generar el gráfico.\")\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(16, 9))\n",
        "    pos = nx.circular_layout(G)\n",
        "    # Colores monocromáticos basados ​​en PageRank\n",
        "    pagerank_values = [data.get('pagerank', 0) for _, data in G.nodes(data=True)]\n",
        "    if pagerank_values:\n",
        "        min_pr = min(pagerank_values)\n",
        "        max_pr = max(pagerank_values)\n",
        "        if max_pr == min_pr:\n",
        "            norm_pr_values = [0.5] * len(pagerank_values)\n",
        "        else:\n",
        "            norm_pr_values = [(p - min_pr) / (max_pr - min_pr) for p in pagerank_values]\n",
        "    else:\n",
        "        norm_pr_values = []\n",
        "\n",
        "    cmap = plt.cm.get_cmap('Blues_r')\n",
        "    node_colors = [cmap(p) for p in norm_pr_values]\n",
        "\n",
        "    # Tamaño del nodo\n",
        "    min_size = 1500\n",
        "    max_size = 16000\n",
        "    if pagerank_values and min_pr == max_pr:\n",
        "        node_sizes = [min_size] * G.number_of_nodes()\n",
        "    elif pagerank_values:\n",
        "        node_sizes = [min_size + ((p - min_pr) / (max_pr - min_pr)) * (max_size - min_size) for p in pagerank_values]\n",
        "    else:\n",
        "        node_sizes = []\n",
        "\n",
        "    custom_labels = {\n",
        "        node: f\"{node.capitalize()}\\n({data.get('occurrences', '?')})\"\n",
        "        for node, data in G.nodes(data=True)\n",
        "    }\n",
        "\n",
        "\n",
        "    nx.draw_networkx_nodes(\n",
        "        G,\n",
        "        pos,\n",
        "        node_color=node_colors,\n",
        "        node_size=node_sizes,\n",
        "        alpha=0.7,\n",
        "        edgecolors='black',\n",
        "        linewidths=1.5\n",
        "    )\n",
        "\n",
        "    nx.draw_networkx_edges(G, pos, alpha=0.3, width=1.5, edge_color='grey')\n",
        "    nx.draw_networkx_labels(G, pos, labels=custom_labels, font_size=12, font_color='black', font_weight='bold')\n",
        "\n",
        "    plt.title(title, size=20)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_filename, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"\\nGráfico '{output_filename}' guardado con éxito!\")\n",
        "\n",
        "## ----------------------------------------------------------------\n",
        "## BLOQUE DE EJECUCIÓN PRINCIPAL\n",
        "## ----------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # --- Parámetros de Entrada ---\n",
        "    FILE_PATH = 'extractos.txt'\n",
        "    TOP_N_NODES = 20\n",
        "    MIN_EDGE_WEIGHT_VIZ = 5 # Ajuste para controlar la densidad de la línea.\n",
        "\n",
        "    GRAFICO_TITULO = \"Análisis de Red Monocromática\"\n",
        "    GRAFICO_OUTPUT_FILE = \"analisis_red_monocromatica.png\"\n",
        "\n",
        "    # --- Ejecución del flujo de trabajo ---\n",
        "    matriz_M = create_cooccurrence_matrix_from_file(FILE_PATH)\n",
        "    grafo_base = nx.from_pandas_adjacency(matriz_M)\n",
        "    grafo_com_metricas = calcular_e_associar_metricas(grafo_base, matriz_M)\n",
        "    grafo_final = filtrar_rede(grafo_com_metricas, top_n=TOP_N_NODES, min_edge_weight_for_viz=MIN_EDGE_WEIGHT_VIZ)\n",
        "    visualizar_rede(grafo_final, GRAFICO_TITULO, GRAFICO_OUTPUT_FILE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLjMLwlpNysn",
        "outputId": "43bb2046-a4ee-4df5-9795-e77460934e0b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Métricas (Cluster, PageRank, Ocorrencias) calculadas y asociadas a los nodos.\n",
            "Red final (Top 20 nodos, Bordes >= 5): 20 nodos, 39 bordes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2503961863.py:116: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
            "  cmap = plt.cm.get_cmap('Blues_r')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Gráfico 'analisis_red_monocromatica.png' guardado con éxito!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "\n",
        "## ----------------------------------------------------------------\n",
        "## FUNCIÓN: Visualización de la Red (Modificada para Clusters)\n",
        "## ----------------------------------------------------------------\n",
        "def visualizar_rede(G, title, output_filename):\n",
        "    if G.number_of_nodes() == 0:\n",
        "        print(\"La red está vacía. No es posible generar el gráfico.\")\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(16, 9))\n",
        "    pos = nx.circular_layout(G)\n",
        "\n",
        "\n",
        "    cluster_values = [data.get('cluster', 0) for _, data in G.nodes(data=True)]\n",
        "    try:\n",
        "        cmap = plt.colormaps.get_cmap('tab10')\n",
        "    except AttributeError:\n",
        "        cmap = plt.cm.get_cmap('tab10')\n",
        "\n",
        "    pagerank_values = [data.get('pagerank', 0) for _, data in G.nodes(data=True)]\n",
        "    min_size = 1500\n",
        "    max_size = 16000\n",
        "\n",
        "    node_sizes = []\n",
        "    if pagerank_values:\n",
        "        min_pr = min(pagerank_values)\n",
        "        max_pr = max(pagerank_values)\n",
        "        if max_pr == min_pr:\n",
        "            node_sizes = [min_size] * G.number_of_nodes()\n",
        "        else:\n",
        "            node_sizes = [\n",
        "                min_size + ((p - min_pr) / (max_pr - min_pr)) * (max_size - min_size)\n",
        "                for p in pagerank_values\n",
        "            ]\n",
        "    else:\n",
        "        node_sizes = [min_size] * G.number_of_nodes()\n",
        "\n",
        "    custom_labels = {\n",
        "        node: f\"{node.capitalize()}\\n({data.get('occurrences', '?')})\"\n",
        "        for node, data in G.nodes(data=True)\n",
        "    }\n",
        "\n",
        "    # Extraer todos los pesos (weights) de las aristas\n",
        "    edge_weights = [data['weight'] for u, v, data in G.edges(data=True)]\n",
        "\n",
        "    base_width = 1.0          # El grosor de la línea más delgada\n",
        "    max_extra_width = 6.0     # Cuánto se añade a la línea más gruesa\n",
        "\n",
        "    scaled_widths = []\n",
        "    if edge_weights:\n",
        "        min_w = min(edge_weights)\n",
        "        max_w = max(edge_weights)\n",
        "\n",
        "        if max_w == min_w:\n",
        "            scaled_widths = [base_width] * len(edge_weights)\n",
        "        else:\n",
        "            for w in edge_weights:\n",
        "                norm_w = (w - min_w) / (max_w - min_w)\n",
        "                scaled_widths.append(base_width + norm_w * max_extra_width)\n",
        "\n",
        "    nx.draw_networkx_nodes(\n",
        "        G,\n",
        "        pos,\n",
        "        node_color=cluster_values,\n",
        "        cmap=cmap,\n",
        "        node_size=node_sizes,\n",
        "        alpha=0.8,\n",
        "        edgecolors='black',\n",
        "        linewidths=1.5\n",
        "    )\n",
        "\n",
        "    nx.draw_networkx_edges(\n",
        "        G,\n",
        "        pos,\n",
        "        alpha=0.3,\n",
        "        width=scaled_widths,\n",
        "        edge_color='grey'\n",
        "    )\n",
        "\n",
        "    nx.draw_networkx_labels(G, pos, labels=custom_labels, font_size=12, font_color='black', font_weight='bold')\n",
        "\n",
        "    plt.title(title, size=20)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_filename, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"\\nGráfico '{output_filename}' guardado con éxito! (Grosor de línea dinámico)\")\n",
        "\n",
        "## ----------------------------------------------------------------\n",
        "## BLOQUE DE EJECUCIÓN PRINCIPAL\n",
        "## ----------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # --- Parámetros de Entrada ---\n",
        "    FILE_PATH = 'extractos.txt'\n",
        "    TOP_N_NODES = 20\n",
        "    MIN_EDGE_WEIGHT_VIZ = 5 # Ajuste para controlar la densidad de la línea.\n",
        "\n",
        "    GRAFICO_TITULO = \"Análisis de Red \"\n",
        "    GRAFICO_OUTPUT_FILE = \"analisis_red_colorida.png\"\n",
        "\n",
        "    # --- Ejecución del flujo de trabajo ---\n",
        "    matriz_M = create_cooccurrence_matrix_from_file(FILE_PATH)\n",
        "    grafo_base = nx.from_pandas_adjacency(matriz_M)\n",
        "    grafo_com_metricas = calcular_e_associar_metricas(grafo_base, matriz_M)\n",
        "    grafo_final = filtrar_rede(grafo_com_metricas, top_n=TOP_N_NODES, min_edge_weight_for_viz=MIN_EDGE_WEIGHT_VIZ)\n",
        "    visualizar_rede(grafo_final, GRAFICO_TITULO, GRAFICO_OUTPUT_FILE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBhO-qkh9zlq",
        "outputId": "7fc08c71-08f3-4e9d-bc2c-f88cdf8c9323"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Métricas (Cluster, PageRank, Ocorrencias) calculadas y asociadas a los nodos.\n",
            "Red final (Top 20 nodos, Bordes >= 5): 20 nodos, 40 bordes.\n",
            "\n",
            "Gráfico 'analisis_red_colorida.png' guardado con éxito! (Grosor de línea dinámico)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "\n",
        "## ----------------------------------------------------------------\n",
        "## FUNCIÓN: Visualización de la Red (Modificada para Clusters)\n",
        "## ----------------------------------------------------------------\n",
        "def visualizar_rede(G, title, output_filename):\n",
        "    if G.number_of_nodes() == 0:\n",
        "        print(\"La red está vacía. No es posible generar el gráfico.\")\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(16, 9))\n",
        "    pos = nx.kamada_kawai_layout(G)\n",
        "\n",
        "\n",
        "    cluster_values = [data.get('cluster', 0) for _, data in G.nodes(data=True)]\n",
        "    try:\n",
        "        cmap = plt.colormaps.get_cmap('tab10')\n",
        "    except AttributeError:\n",
        "        cmap = plt.cm.get_cmap('tab10')\n",
        "\n",
        "    pagerank_values = [data.get('pagerank', 0) for _, data in G.nodes(data=True)]\n",
        "    min_size = 1500\n",
        "    max_size = 16000\n",
        "\n",
        "    node_sizes = []\n",
        "    if pagerank_values:\n",
        "        min_pr = min(pagerank_values)\n",
        "        max_pr = max(pagerank_values)\n",
        "        if max_pr == min_pr:\n",
        "            node_sizes = [min_size] * G.number_of_nodes()\n",
        "        else:\n",
        "            node_sizes = [\n",
        "                min_size + ((p - min_pr) / (max_pr - min_pr)) * (max_size - min_size)\n",
        "                for p in pagerank_values\n",
        "            ]\n",
        "    else:\n",
        "        node_sizes = [min_size] * G.number_of_nodes()\n",
        "\n",
        "    custom_labels = {\n",
        "        node: f\"{node.capitalize()}\\n({data.get('occurrences', '?')})\"\n",
        "        for node, data in G.nodes(data=True)\n",
        "    }\n",
        "\n",
        "    # Extraer todos los pesos (weights) de las aristas\n",
        "    edge_weights = [data['weight'] for u, v, data in G.edges(data=True)]\n",
        "\n",
        "    base_width = 1.0          # El grosor de la línea más delgada\n",
        "    max_extra_width = 6.0     # Cuánto se añade a la línea más gruesa\n",
        "\n",
        "    scaled_widths = []\n",
        "    if edge_weights:\n",
        "        min_w = min(edge_weights)\n",
        "        max_w = max(edge_weights)\n",
        "\n",
        "        if max_w == min_w:\n",
        "            scaled_widths = [base_width] * len(edge_weights)\n",
        "        else:\n",
        "            for w in edge_weights:\n",
        "                norm_w = (w - min_w) / (max_w - min_w)\n",
        "                scaled_widths.append(base_width + norm_w * max_extra_width)\n",
        "\n",
        "    nx.draw_networkx_nodes(\n",
        "        G,\n",
        "        pos,\n",
        "        node_color=cluster_values,\n",
        "        cmap=cmap,\n",
        "        node_size=node_sizes,\n",
        "        alpha=0.8,\n",
        "        edgecolors='black',\n",
        "        linewidths=1.5\n",
        "    )\n",
        "\n",
        "    nx.draw_networkx_edges(\n",
        "        G,\n",
        "        pos,\n",
        "        alpha=0.3,\n",
        "        width=scaled_widths,\n",
        "        edge_color='grey'\n",
        "    )\n",
        "\n",
        "    nx.draw_networkx_labels(G, pos, labels=custom_labels, font_size=12, font_color='black', font_weight='bold')\n",
        "\n",
        "    plt.title(title, size=20)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_filename, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"\\nGráfico '{output_filename}' guardado con éxito! (Grosor de línea dinámico)\")\n",
        "\n",
        "## ----------------------------------------------------------------\n",
        "## BLOQUE DE EJECUCIÓN PRINCIPAL\n",
        "## ----------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # --- Parámetros de Entrada ---\n",
        "    FILE_PATH = 'extractos.txt'\n",
        "    TOP_N_NODES = 20\n",
        "    MIN_EDGE_WEIGHT_VIZ = 4 # Ajuste para controlar la densidad de la línea.\n",
        "\n",
        "    GRAFICO_TITULO = \"Análisis de Red\"\n",
        "    GRAFICO_OUTPUT_FILE = \"analisis_red_colorida_Kamada.png\"\n",
        "\n",
        "    # --- Ejecución del flujo de trabajo ---\n",
        "    matriz_M = create_cooccurrence_matrix_from_file(FILE_PATH)\n",
        "    grafo_base = nx.from_pandas_adjacency(matriz_M)\n",
        "    grafo_com_metricas = calcular_e_associar_metricas(grafo_base, matriz_M)\n",
        "    grafo_final = filtrar_rede(grafo_com_metricas, top_n=TOP_N_NODES, min_edge_weight_for_viz=MIN_EDGE_WEIGHT_VIZ)\n",
        "    visualizar_rede(grafo_final, GRAFICO_TITULO, GRAFICO_OUTPUT_FILE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_A9eg3J6F6K",
        "outputId": "5b0ac9c9-fb37-48c1-a3e1-af32b434a5bd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Métricas (Cluster, PageRank, Ocorrencias) calculadas y asociadas a los nodos.\n",
            "Red final (Top 20 nodos, Bordes >= 4): 20 nodos, 54 bordes.\n",
            "\n",
            "Gráfico 'analisis_red_colorida_Kamada.png' guardado con éxito! (Grosor de línea dinámico)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "\n",
        "## ----------------------------------------------------------------\n",
        "## FUNCIÓN: Visualización de la Red (Monocromática + Grosor Dinámico)\n",
        "## ----------------------------------------------------------------\n",
        "def visualizar_rede(G, title, output_filename):\n",
        "\n",
        "    if G.number_of_nodes() == 0:\n",
        "        print(\"La red está vacía. No es posible generar el gráfico.\")\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(16, 9))\n",
        "\n",
        "    pos = nx.kamada_kawai_layout(G)\n",
        "\n",
        "    # --- Lógica de Tamaño y Color (PageRank) ---\n",
        "    pagerank_values = [data.get('pagerank', 0) for _, data in G.nodes(data=True)]\n",
        "\n",
        "    # --- Lógica de Tamaño ---\n",
        "    min_size = 1500\n",
        "    max_size = 16000\n",
        "    node_sizes = []\n",
        "    if pagerank_values:\n",
        "        min_pr = min(pagerank_values)\n",
        "        max_pr = max(pagerank_values)\n",
        "        if max_pr == min_pr:\n",
        "            node_sizes = [min_size] * G.number_of_nodes()\n",
        "        else:\n",
        "            node_sizes = [\n",
        "                min_size + ((p - min_pr) / (max_pr - min_pr)) * (max_size - min_size)\n",
        "                for p in pagerank_values\n",
        "            ]\n",
        "    else:\n",
        "        node_sizes = [min_size] * G.number_of_nodes()\n",
        "\n",
        "\n",
        "    try:\n",
        "        cmap_color = plt.colormaps.get_cmap('Blues_r')\n",
        "    except AttributeError:\n",
        "        # Para versiones antiguas de Matplotlib\n",
        "        cmap_color = plt.cm.get_cmap('Blues_r')\n",
        "\n",
        "    # --- (MANTENIDO) Lógica de Grosor de Línea (Peso de Arista) ---\n",
        "    edge_weights = [data['weight'] for u, v, data in G.edges(data=True)]\n",
        "    base_width = 1.0\n",
        "    max_extra_width = 6.0\n",
        "    scaled_widths = []\n",
        "    if edge_weights:\n",
        "        min_w = min(edge_weights)\n",
        "        max_w = max(edge_weights)\n",
        "        if max_w == min_w:\n",
        "            scaled_widths = [base_width] * len(edge_weights)\n",
        "        else:\n",
        "            scaled_widths = [\n",
        "                base_width + (((w - min_w) / (max_w - min_w)) * max_extra_width)\n",
        "                for w in edge_weights\n",
        "            ]\n",
        "    else:\n",
        "        scaled_widths = [base_width] * len(edge_weights)\n",
        "\n",
        "    custom_labels = {\n",
        "        node: f\"{node.capitalize()}\\n({data.get('occurrences', '?')})\"\n",
        "        for node, data in G.nodes(data=True)\n",
        "    }\n",
        "\n",
        "    # --- Dibujar Nodos ---\n",
        "    nx.draw_networkx_nodes(\n",
        "        G,\n",
        "        pos,\n",
        "        node_color=pagerank_values,\n",
        "        cmap=cmap_color,\n",
        "        # ---\n",
        "        node_size=node_sizes,\n",
        "        alpha=0.8,\n",
        "        edgecolors='black',\n",
        "        linewidths=1.5\n",
        "    )\n",
        "\n",
        "    # --- Dibujar Aristas ---\n",
        "    nx.draw_networkx_edges(\n",
        "        G,\n",
        "        pos,\n",
        "        alpha=0.3,\n",
        "        width=scaled_widths,  # <-- Se mantiene el grosor dinámico\n",
        "        edge_color='grey'\n",
        "    )\n",
        "\n",
        "    # --- Dibujar Etiquetas ---\n",
        "    nx.draw_networkx_labels(G, pos, labels=custom_labels, font_size=12, font_color='black', font_weight='bold')\n",
        "\n",
        "    plt.title(title, size=20)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_filename, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"\\nGráfico '{output_filename}' guardado con éxito! (Monocromático y grosor dinámico)\")\n",
        "## ----------------------------------------------------------------\n",
        "## BLOQUE DE EJECUCIÓN PRINCIPAL\n",
        "## ----------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # --- Parámetros de Entrada ---\n",
        "    FILE_PATH = 'extractos.txt'\n",
        "    TOP_N_NODES = 20\n",
        "    MIN_EDGE_WEIGHT_VIZ = 5 # Ajuste para controlar la densidad de la línea.\n",
        "\n",
        "    GRAFICO_TITULO = \"Análisis de Red\"\n",
        "    GRAFICO_OUTPUT_FILE = \"analisis_red_monocromática_Kamada.png\"\n",
        "\n",
        "    # --- Ejecución del flujo de trabajo ---\n",
        "    matriz_M = create_cooccurrence_matrix_from_file(FILE_PATH)\n",
        "    grafo_base = nx.from_pandas_adjacency(matriz_M)\n",
        "    grafo_com_metricas = calcular_e_associar_metricas(grafo_base, matriz_M)\n",
        "    grafo_final = filtrar_rede(grafo_com_metricas, top_n=TOP_N_NODES, min_edge_weight_for_viz=MIN_EDGE_WEIGHT_VIZ)\n",
        "    visualizar_rede(grafo_final, GRAFICO_TITULO, GRAFICO_OUTPUT_FILE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXYDNliVEFDb",
        "outputId": "21c0af6f-7328-4526-c6cf-304ea929f2bd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Métricas (Cluster, PageRank, Ocorrencias) calculadas y asociadas a los nodos.\n",
            "Red final (Top 20 nodos, Bordes >= 5): 20 nodos, 39 bordes.\n",
            "\n",
            "Gráfico 'analisis_red_monocromática_Kamada.png' guardado con éxito! (Monocromático y grosor dinámico)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## ----------------------------------------------------------------\n",
        "## BLOQUE DE EJECUCIÓN PRINCIPAL (CON PASO DE EDICIÓN)\n",
        "## ----------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # --- Parámetros de Entrada ---\n",
        "    FILE_PATH = 'extractos.txt'\n",
        "    TOP_N_NODES = 20\n",
        "    MIN_EDGE_WEIGHT_VIZ = 5\n",
        "    GRAFICO_TITULO = \"Análisis de Red (Clusters y Correlación)\"\n",
        "    GRAFICO_OUTPUT_FILE = \"analisis_red_clusters.png\"\n",
        "\n",
        "    # Nombre del archivo para editar las etiquetas\n",
        "    MAPEO_ETIQUETAS_FILE = 'mapeo_terminos.csv'\n",
        "\n",
        "    # --- 1. Flujo de trabajo estándar (hasta el filtrado) ---\n",
        "    print(\"Iniciando análisis...\")\n",
        "    matriz_M = create_cooccurrence_matrix_from_file(FILE_PATH)\n",
        "    grafo_base = nx.from_pandas_adjacency(matriz_M)\n",
        "    grafo_com_metricas = calcular_e_associar_metricas(grafo_base, matriz_M)\n",
        "    grafo_final = filtrar_rede(grafo_com_metricas, top_n=TOP_N_NODES, min_edge_weight_for_viz=MIN_EDGE_WEIGHT_VIZ)\n",
        "\n",
        "    # --- 2. (NUEVO) Exportar nodos para corrección de tildes ---\n",
        "\n",
        "    # Obtener la lista de nodos del grafo final\n",
        "    nodos_sin_tildes = list(grafo_final.nodes())\n",
        "\n",
        "    # Crear un DataFrame de Pandas: original -> corregido\n",
        "    # Inicialmente, ambas columnas son iguales.\n",
        "    df_mapa = pd.DataFrame({\n",
        "        'original_sin_tilde': nodos_sin_tildes,\n",
        "        'corregido_con_tilde': nodos_sin_tildes\n",
        "    })\n",
        "\n",
        "    # Guardar en un archivo CSV\n",
        "    df_mapa.to_csv(MAPEO_ETIQUETAS_FILE, index=False, encoding='utf-8-sig')\n",
        "\n",
        "    # --- 3. (NUEVO) Pausa para la edición manual ---\n",
        "    print(\"-\" * 70)\n",
        "    print(f\"ARCHIVO CREADO: '{MAPEO_ETIQUETAS_FILE}'\")\n",
        "    print(\"Por favor, abre este archivo CSV (con Excel, Google Sheets, o un editor de texto).\")\n",
        "    print(\"Modifica la columna 'corregido_con_tilde' para añadir las tildes necesarias.\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    # Pausa el script y espera a que el usuario presione Enter\n",
        "    input(\">>> PRESIONA ENTER para continuar después de guardar tus cambios... \")\n",
        "\n",
        "    # --- 4. (NUEVO) Importar mapa corregido y re-etiquetar ---\n",
        "    print(\"Leyendo el archivo de etiquetas corregido...\")\n",
        "\n",
        "    # Leer el archivo que acabas de editar\n",
        "    try:\n",
        "        df_mapa_editado = pd.read_csv(MAPEO_ETIQUETAS_FILE, encoding='utf-8-sig')\n",
        "    except Exception as e:\n",
        "        print(f\"Error leyendo el archivo {MAPEO_ETIQUETAS_FILE}: {e}\")\n",
        "        print(\"Asegúrate de que el archivo esté guardado correctamente.\")\n",
        "        exit()\n",
        "\n",
        "    # Crear el diccionario de mapeo\n",
        "    # (ej. {'investigacion': 'investigación', 'docente': 'docente', ...})\n",
        "    mapa_de_etiquetas = pd.Series(\n",
        "        df_mapa_editado.corregido_con_tilde.values,\n",
        "        index=df_mapa_editado.original_sin_tilde\n",
        "    ).to_dict()\n",
        "\n",
        "    # Aplicar el re-etiquetado al grafo\n",
        "    grafo_etiquetado = nx.relabel_nodes(grafo_final, mapa_de_etiquetas, copy=True)\n",
        "\n",
        "    print(\"Nodos re-etiquetados con éxito.\")\n",
        "\n",
        "    # --- 5. Ejecución del flujo de trabajo (Visualización) ---\n",
        "    visualizar_rede(\n",
        "        grafo_etiquetado,  # <--- Usamos el nuevo grafo con tildes\n",
        "        GRAFICO_TITULO,\n",
        "        GRAFICO_OUTPUT_FILE\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aswELxp8AO-K",
        "outputId": "ce611770-7c90-4cd1-e1f2-24878c008b2f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando análisis...\n",
            "Métricas (Cluster, PageRank, Ocorrencias) calculadas y asociadas a los nodos.\n",
            "Red final (Top 20 nodos, Bordes >= 5): 20 nodos, 40 bordes.\n",
            "----------------------------------------------------------------------\n",
            "ARCHIVO CREADO: 'mapeo_terminos.csv'\n",
            "Por favor, abre este archivo CSV (con Excel, Google Sheets, o un editor de texto).\n",
            "Modifica la columna 'corregido_con_tilde' para añadir las tildes necesarias.\n",
            "----------------------------------------------------------------------\n",
            ">>> PRESIONA ENTER para continuar después de guardar tus cambios... \n",
            "Leyendo el archivo de etiquetas corregido...\n",
            "Nodos re-etiquetados con éxito.\n",
            "\n",
            "Gráfico 'analisis_red_clusters.png' guardado con éxito! (Grosor de línea dinámico)\n"
          ]
        }
      ]
    }
  ]
}